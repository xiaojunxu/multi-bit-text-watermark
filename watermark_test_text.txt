We propose an imperceptible multi-bit text watermark embedded by paraphrasing with LLMs. We fine-tune a pair of LLM paraphrasers that are designed to behave differently so that their paraphrasing difference reflected in the text semantics can be identified by a trained decoder. To embed our multi-bit watermark, we use two paraphrasers alternatively to encode the pre-defined binary code at the sentence level. Then we use a text classifier as the decoder to decode each bit of the watermark. Through extensive experiments, we show that our watermarks can achieve over 99.99\% detection AUC with small (1.1B) text paraphrasers while keeping the semantic information of the original sentence. More importantly, our pipeline is robust under word substitution and sentence paraphrasing perturbations and generalizes well to out-of-distributional data. We also show the stealthiness of our watermark with LLM-based evaluation. We open-source the code: this https URL.

===============

我们提出了一种通过大语言模型（LLMs）改写嵌入的多比特文本水印方法。我们微调了两个基于LLM的文本改写器，使其改写后文本语义上的差异能够被训练好的解码器识别。为了嵌入多比特水印，我们在句子层面交替使用两个改写器来编码预定义的二进制码。随后，我们使用文本分类器作为解码器来解码水印的每一比特。通过大量实验，我们展示了使用规模较小（1.1B参数）改写器时，水印检测的AUC可达99.99%以上，同时保持了原句的语义信息。更重要的是，我们的方法在词语替换和句子改写扰动下具有鲁棒性，并且能良好泛化到分布外数据。我们还通过基于LLM的评估展示了水印的隐蔽性。代码已开源，链接为：https URL。
